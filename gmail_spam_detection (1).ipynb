{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b8406545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fc0d17a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = pd.read_csv('spam1.csv')\n",
    "dt.pop(\"Unnamed: 3\")\n",
    "dt.pop(\"Unnamed: 2\")\n",
    "dt.pop(\"Unnamed: 4\")\n",
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "762c000d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2  spam\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
       "1   ham                      Ok lar... Joking wif u oni...     0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3   ham  U dun say so early hor... U c already then say...     0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...     0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dt['spam'] = dt['v1'].map({'spam' : 1, \"ham\" : 0}).astype(int)\n",
    "dt.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "155a93ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns in the given table are :\n",
      "v1\n",
      "v2\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "#printing the colums in the folder\n",
    "print(\"columns in the given table are :\")\n",
    "for i in dt.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fbe5c445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of rows type column 5572\n",
      "no of rows in text column : 5572\n"
     ]
    }
   ],
   "source": [
    "#finding the no.of rows in the type and text\n",
    "t=len(dt['v1'])\n",
    "print(\"no.of rows type column\",t)\n",
    "t=len(dt['v2'])\n",
    "print(\"no of rows in text column :\",t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf8943",
   "metadata": {},
   "source": [
    "# from here we convert the whole text to tokens called as tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "676be0fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok lar... Joking wif u oni...'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['v2'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ad694bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cebb6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['v2'] = dt['v2'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cbecd78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ok', 'lar...', 'Joking', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['v2'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b6de7f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "#it means that the removing additional suffix or prefixes : all having the same name\n",
    "#for example waits, waiting,waited are all same sow e apply stemming making all to on word wait\n",
    "# there are three types of stemmer snowball,porter,landcaster out of which snowball is latest and fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91dfaa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "porter = SnowballStemmer(\"english\", ignore_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2cecff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_it(v2):\n",
    "    return [porter.stem(word) for word in v2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e745af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['v2']=dt['v2'].apply(stem_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cce75f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok', 'lar...', 'joke', 'wif', 'u', 'oni...']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['v2'][1] #this code is after the stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8117c3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok...', 'ur', 'typic', 'reply...']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['v2'][152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "72c128fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6c91100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmit_it(v2):\n",
    "    return [lemmatizer.lemmatize(word,pos=\"a\") for word in v2] #here a denotes adjective in position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b720ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['v2']=dt['v2'].apply(lemmit_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f8ef9d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok...', 'ur', 'typic', 'reply...']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['v2'][152]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c9c9a5",
   "metadata": {},
   "source": [
    "# STOP WORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40e31df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tired.', 'i', \"haven't\", 'slept', 'well', 'the', 'past', 'few', 'nights.']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['v2'][216] # this is before stop word removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "abb197b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8c177dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "30ea71ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_it(v2):\n",
    "    review = [word for word in v2 if not word in stop_words ]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "266c7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"v2\"] = dt[\"v2\"].apply(stop_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "04032506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tired.', 'slept', 'well', 'past', 'nights.']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['v2'][216] # afetr stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1927dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, jurong, point,, crazy.., avail, onli, bug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar..., joke, wif, u, oni...]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, earli, hor..., u, c, alreadi, sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, think, goe, usf,, live, around, though]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, hey, darl, 3, week, word, back!, i'd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>[even, brother, like, speak, me., treat, like,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>[per, request, mell, mell, (oru, minnaminungin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>[winner!!, valu, network, custom, select, rece...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>[mobil, 11, month, more?, u, r, entitl, updat,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i'm, gonna, home, soon, want, talk, stuff, an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>[six, chanc, win, cash!, 100, 20,000, pound, t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>[urgent!, 1, week, free, membership, �100,000,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i'v, search, right, word, thank, breather., p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>[date, sunday, will!!]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2  spam\n",
       "0    ham  [go, jurong, point,, crazy.., avail, onli, bug...     0\n",
       "1    ham                 [ok, lar..., joke, wif, u, oni...]     0\n",
       "2   spam  [free, entri, 2, wkli, comp, win, fa, cup, fin...     1\n",
       "3    ham  [u, dun, say, earli, hor..., u, c, alreadi, sa...     0\n",
       "4    ham      [nah, think, goe, usf,, live, around, though]     0\n",
       "5   spam  [freemsg, hey, darl, 3, week, word, back!, i'd...     1\n",
       "6    ham  [even, brother, like, speak, me., treat, like,...     0\n",
       "7    ham  [per, request, mell, mell, (oru, minnaminungin...     0\n",
       "8   spam  [winner!!, valu, network, custom, select, rece...     1\n",
       "9   spam  [mobil, 11, month, more?, u, r, entitl, updat,...     1\n",
       "10   ham  [i'm, gonna, home, soon, want, talk, stuff, an...     0\n",
       "11  spam  [six, chanc, win, cash!, 100, 20,000, pound, t...     1\n",
       "12  spam  [urgent!, 1, week, free, membership, �100,000,...     1\n",
       "13   ham  [i'v, search, right, word, thank, breather., p...     0\n",
       "14   ham                             [date, sunday, will!!]     0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f180b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt['v2'] = dt['v2'].apply(' '.join)  #adds up space and joins all the words in it\n",
    "#string.join()  ==> whatever the string is the join joins the list with that string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e3bafd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go jurong point, crazy.. avail onli bugi n gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joke wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkts 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say earli hor... u c alreadi say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah think goe usf, live around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>freemsg hey darl 3 week word back! i'd like fu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>even brother like speak me. treat like aid pat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>per request mell mell (oru minnaminungint nuru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>winner!! valu network custom select receivea �...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>mobil 11 month more? u r entitl updat late col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>i'm gonna home soon want talk stuff anymor ton...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>six chanc win cash! 100 20,000 pound txt&gt; csh1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>urgent! 1 week free membership �100,000 prize ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>i'v search right word thank breather. promis w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>date sunday will!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2  spam\n",
       "0    ham  go jurong point, crazy.. avail onli bugi n gre...     0\n",
       "1    ham                        ok lar... joke wif u oni...     0\n",
       "2   spam  free entri 2 wkli comp win fa cup final tkts 2...     1\n",
       "3    ham          u dun say earli hor... u c alreadi say...     0\n",
       "4    ham              nah think goe usf, live around though     0\n",
       "5   spam  freemsg hey darl 3 week word back! i'd like fu...     1\n",
       "6    ham  even brother like speak me. treat like aid pat...     0\n",
       "7    ham  per request mell mell (oru minnaminungint nuru...     0\n",
       "8   spam  winner!! valu network custom select receivea �...     1\n",
       "9   spam  mobil 11 month more? u r entitl updat late col...     1\n",
       "10   ham  i'm gonna home soon want talk stuff anymor ton...     0\n",
       "11  spam  six chanc win cash! 100 20,000 pound txt> csh1...     1\n",
       "12  spam  urgent! 1 week free membership �100,000 prize ...     1\n",
       "13   ham  i'v search right word thank breather. promis w...     0\n",
       "14   ham                                 date sunday will!!     0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca15b6b",
   "metadata": {},
   "source": [
    "# TIME TO CONVERT TEXT DATA INTO MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c3fc9a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 8077)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "y = dt.spam\n",
    "X = tfidf.fit_transform(dt['v2'])\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2238c8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c2be5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_text,y_train,y_text = train_test_split(X,y,random_state=1,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62f942",
   "metadata": {},
   "source": [
    "# Logistic_Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "af4d8267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is  96.50224215246637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_text)\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_log = accuracy_score(y_pred,y_text)*100\n",
    "print(\"it is \",acc_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a5dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
